{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 運用這幾天所學觀念搭建一個CNN分類器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 熟悉CNN分類器搭建步驟與原理\n",
    "  #### 學員們可以嘗試不同搭法，如使用不同的Maxpooling層，用GlobalAveragePooling取代Flatten等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7) \n",
    "        return X_train, X_test,mean,std\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test,mean_train,std_train = normalize(x_train, x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot=OneHotEncoder()\n",
    "y_train=one_hot.fit_transform(y_train).toarray()\n",
    "y_test=one_hot.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 13, 13, 32)        128       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               540900    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 552,310\n",
      "Trainable params: 552,182\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n"
     ]
    }
   ],
   "source": [
    "classifier=Sequential()\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32,(3,3),activation='relu',input_shape=(32,32,3)))#32,3,3,input_shape=(32,32,3),activation='relu''\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "# 池化\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32, kernel_size=(3,3)))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "#flatten\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#FC\n",
    "classifier.add(Dense(100, activation='relu')) #output_dim=100,activation=relu\n",
    "\n",
    "#輸出\n",
    "classifier.add(Dense(output_dim=10,activation='softmax'))\n",
    "\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 1.3667 - accuracy: 0.5445\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 0.8857 - accuracy: 0.6924\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.7039 - accuracy: 0.7539\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.5680 - accuracy: 0.8024\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.4558 - accuracy: 0.8408\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 0.3607 - accuracy: 0.8743\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 0.2752 - accuracy: 0.9043\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 0.2127 - accuracy: 0.9266\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.1859 - accuracy: 0.9354\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.1649 - accuracy: 0.9429\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.1368 - accuracy: 0.9523\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.1121 - accuracy: 0.9600\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 0.1118 - accuracy: 0.9625\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.1078 - accuracy: 0.9637\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.1112 - accuracy: 0.9619\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 0.0891 - accuracy: 0.9699\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.0730 - accuracy: 0.9750\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0856 - accuracy: 0.9703\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0874 - accuracy: 0.9702\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 80s 2ms/step - loss: 0.0704 - accuracy: 0.9764\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 0.0630 - accuracy: 0.9790\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.0624 - accuracy: 0.9789\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.0665 - accuracy: 0.9779\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.0676 - accuracy: 0.9776\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.0558 - accuracy: 0.9814\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.0639 - accuracy: 0.9786\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.0667 - accuracy: 0.9773\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.0677 - accuracy: 0.9780\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.0466 - accuracy: 0.9850\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 75s 1ms/step - loss: 0.0403 - accuracy: 0.9864\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.0492 - accuracy: 0.9837\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.0494 - accuracy: 0.9836\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.0474 - accuracy: 0.9832\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0486 - accuracy: 0.9844\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 0.0494 - accuracy: 0.9835\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 75s 2ms/step - loss: 0.0318 - accuracy: 0.9891\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 76s 2ms/step - loss: 0.0390 - accuracy: 0.9875\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 0.0487 - accuracy: 0.9836\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0459 - accuracy: 0.9855\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 0.0392 - accuracy: 0.9868\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.0410 - accuracy: 0.9865\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0423 - accuracy: 0.9869\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.0369 - accuracy: 0.9882\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 0.0378 - accuracy: 0.9878\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0394 - accuracy: 0.9874\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0302 - accuracy: 0.9901\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.0314 - accuracy: 0.9896\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.0315 - accuracy: 0.9899\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.0401 - accuracy: 0.9872\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 0.0343 - accuracy: 0.9886\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 0.0303 - accuracy: 0.9902\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 0.0326 - accuracy: 0.9895\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 0.0220 - accuracy: 0.9930\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.0315 - accuracy: 0.9892\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0343 - accuracy: 0.9890\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 72s 1ms/step - loss: 0.0364 - accuracy: 0.9880\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.0370 - accuracy: 0.9885\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 75s 1ms/step - loss: 0.0227 - accuracy: 0.9925\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 0.0234 - accuracy: 0.9919\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.0258 - accuracy: 0.9921\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0297 - accuracy: 0.9905\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 77s 2ms/step - loss: 0.0290 - accuracy: 0.9910\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 0.0325 - accuracy: 0.9900\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 76s 2ms/step - loss: 0.0237 - accuracy: 0.9925\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 75s 2ms/step - loss: 0.0289 - accuracy: 0.9911\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 75s 2ms/step - loss: 0.0218 - accuracy: 0.9926\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 0.0282 - accuracy: 0.9912\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 0.0200 - accuracy: 0.9938\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 76s 2ms/step - loss: 0.0259 - accuracy: 0.9916\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 0.0195 - accuracy: 0.9937\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 0.0230 - accuracy: 0.9922\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 81s 2ms/step - loss: 0.0310 - accuracy: 0.9903\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 82s 2ms/step - loss: 0.0189 - accuracy: 0.9942\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 83s 2ms/step - loss: 0.0248 - accuracy: 0.9922\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 75s 1ms/step - loss: 0.0208 - accuracy: 0.9937\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0239 - accuracy: 0.9925\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 82s 2ms/step - loss: 0.0187 - accuracy: 0.9940\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 0.0187 - accuracy: 0.9942\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 77s 2ms/step - loss: 0.0252 - accuracy: 0.9917\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 0.0238 - accuracy: 0.9924\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 86s 2ms/step - loss: 0.0244 - accuracy: 0.9921\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 75s 2ms/step - loss: 0.0187 - accuracy: 0.9942\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 75s 1ms/step - loss: 0.0250 - accuracy: 0.9923\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 77s 2ms/step - loss: 0.0190 - accuracy: 0.9936\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0254 - accuracy: 0.9920\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 75s 1ms/step - loss: 0.0217 - accuracy: 0.9930\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 77s 2ms/step - loss: 0.0146 - accuracy: 0.9952\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 79s 2ms/step - loss: 0.0192 - accuracy: 0.9939\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0186 - accuracy: 0.9940\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 0.99 - 79s 2ms/step - loss: 0.0112 - accuracy: 0.9964\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 0.0184 - accuracy: 0.9942\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 76s 2ms/step - loss: 0.0283 - accuracy: 0.9915\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 76s 2ms/step - loss: 0.0220 - accuracy: 0.9931\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0200 - accuracy: 0.9934\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 80s 2ms/step - loss: 0.0167 - accuracy: 0.9947\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 77s 2ms/step - loss: 0.0119 - accuracy: 0.9965\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 77s 2ms/step - loss: 0.0196 - accuracy: 0.9938\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 79s 2ms/step - loss: 0.0230 - accuracy: 0.9926\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 99s 2ms/step - loss: 0.0169 - accuracy: 0.9948\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 83s 2ms/step - loss: 0.0065 - accuracy: 0.9980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2119123ef48>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(x_train,y_train,batch_size=100,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預測新圖片，輸入影像前處理要與訓練時相同\n",
    "#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n",
    "## 維度如下方示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.9563852e-06, 5.9379355e-12, 2.0719970e-08, 9.9999177e-01,\n",
       "        2.3096298e-07, 8.5248199e-15, 2.5063644e-09, 7.0741830e-09,\n",
       "        1.9541108e-10, 3.2624636e-16]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example=(np.zeros(shape=(1,32,32,3))-mean_train)/(std_train+1e-7) \n",
    "classifier.predict(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
